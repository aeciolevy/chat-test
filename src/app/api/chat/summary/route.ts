// route.ts Route Handlers
import OpenAI from "openai";
import { NextResponse } from "next/server";
import { NextApiResponse } from "next";

export const runtime = 'edge'; // Provide optimal infrastructure for our API route (https://edge-runtime.vercel.app/)

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

export async function POST(request: Request, response: NextApiResponse) {
    console.log('### request summary API');
    const { messages } = await request.json(); // { messages: [] }
    console.log('### messages', messages);
    const mapMessages = messages.map((message) => {
        return {
            role: message.role,
            content: message.content
        };
    })

    console.log('### mapMessages', mapMessages);
    // createChatCompletion (get response from GPT-4)
    const gptSummary = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
            { role: "system", content: `You will provide a summary of the feedback regarding the floorplan generated by Market.`},
            ...mapMessages
        ]
    })

    console.log('### response server', response);
    //return response;
    return NextResponse.json(gptSummary.choices[0].message.content);
}
